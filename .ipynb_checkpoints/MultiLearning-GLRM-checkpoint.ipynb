{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8541f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import MultiLearn_GLRM\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d51f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Experiments/ESLR/prostate/prostate.data', delimiter='\\t', index_col=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "mask_train = df.pop('train')\n",
    "df_y = df.pop('lpsa')\n",
    "\n",
    "X_train = df[mask_train == 'T']\n",
    "Y_train = df_y[mask_train == 'T']\n",
    "Y_train = np.array(Y_train).reshape(-1,1)\n",
    "\n",
    "\n",
    "X_test = df[mask_train != 'T']\n",
    "Y_test = df_y[mask_train != 'T']\n",
    "Y_test = np.array(Y_test).reshape(-1,1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "params = {\n",
    "    \"train_hyper_params\": None,\n",
    "    \"test_hyper_params\": None,\n",
    "    \"beta\": None,\n",
    "    \"embedding_matrix\": None,\n",
    "    \"train_error\": None,\n",
    "    \"test_error\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96597f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "iter: 285 Total loss: tf.Tensor(5.327115490631575, shape=(), dtype=float64)\n",
      "iter: 132 Total loss: tf.Tensor(2.331980802773805, shape=(), dtype=float64)\n",
      "epoch: 1\n",
      "iter: 191 Total loss: tf.Tensor(1.0294332264630728, shape=(), dtype=float64)\n",
      "iter: 26 Total loss: tf.Tensor(0.8280117484845101, shape=(), dtype=float64)\n",
      "epoch: 2\n",
      "iter: 54 Total loss: tf.Tensor(0.763319267141003, shape=(), dtype=float64)\n",
      "iter: 7 Total loss: tf.Tensor(0.7545463414694018, shape=(), dtype=float64)\n",
      "epoch: 3\n",
      "iter: 1 Total loss: tf.Tensor(0.7535850846125428, shape=(), dtype=float64)\n",
      "iter: 1 Total loss: tf.Tensor(0.7527082388632406, shape=(), dtype=float64)\n",
      "epoch: 3 Total loss: tf.Tensor(0.752574059070822, shape=(), dtype=float64)\n",
      "Final loss: tf.Tensor(0.752574059070822, shape=(), dtype=float64) best loss: tf.Tensor(0.752574059070822, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "reload(MultiLearn_GLRM)\n",
    "from MultiLearn_GLRM import Multi_Learn, generate_AXY\n",
    "from MultiLearn_GLRM.Params.semisupervised_params import Multilearn_GLRM_Semisupervised_Train_Params, Multilearn_GLRM_Semisupervised_Test_Params\n",
    "\n",
    "embedding_dim = 5\n",
    "n_class = 1\n",
    "\n",
    "A_prime, X_prime, Y_prime = generate_AXY.get_semisupervised_glrm_train_form(X_train, Y_train, n_class, embedding_dim)\n",
    "[GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions] = Multilearn_GLRM_Semisupervised_Train_Params(A_prime, X_prime, Y_prime, n_class)\n",
    "\n",
    "params[\"train_hyper_params\"] = [GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions]\n",
    "\n",
    "num_iterations=100000\n",
    "learning_rate=0.01\n",
    "result = Multi_Learn.alternating_minimization(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions, num_iterations, learning_rate, n_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41d4c693",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n        'EagerTensor' object has no attribute 'tolist'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m beta \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m0\u001b[39m:n_class]\n\u001b[1;32m      2\u001b[0m Y_final \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:embedding_dim\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,n_class:]\n\u001b[0;32m----> 3\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m()\n\u001b[1;32m      4\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Y_final\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(result[\u001b[38;5;241m0\u001b[39m], result[\u001b[38;5;241m1\u001b[39m][:,\u001b[38;5;241m0\u001b[39m:n_class])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:508\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    506\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124m      If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124m      from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124m      np_config.enable_numpy_behavior()\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m    513\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'tolist'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()"
     ]
    }
   ],
   "source": [
    "beta = result[1][1:,0:n_class]\n",
    "Y_final = result[1][1:embedding_dim+1,n_class:]\n",
    "params[\"beta\"] = beta\n",
    "params[\"embedding_matrix\"] = Y_final\n",
    "\n",
    "res = np.matmul(result[0], result[1][:,0:n_class])\n",
    "params[\"train_error\"] = np.mean((Y_train - res)**2)\n",
    "params[\"train_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558196dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = np.matmul(result[0], result[1][:,0:n_class])\n",
    "# np.mean((Y_train - res)**2)\n",
    "# 0.4495674496068231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6761625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, Y_train.shape[0]):\n",
    "    print(Y_train[i], res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "918b960c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Total loss: tf.Tensor(1.7839785601865006, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7881735309361646, shape=(), dtype=float64)\n",
      "iter: 188 Total loss: tf.Tensor(0.7229102476001684, shape=(), dtype=float64)\n",
      "0.4886293920025888\n",
      "iter: 0 Total loss: tf.Tensor(1.6584282985687404, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7606804172697872, shape=(), dtype=float64)\n",
      "iter: 171 Total loss: tf.Tensor(0.722391689086041, shape=(), dtype=float64)\n",
      "0.4882871028217626\n",
      "iter: 0 Total loss: tf.Tensor(1.64467615896816, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7706985393040839, shape=(), dtype=float64)\n",
      "iter: 178 Total loss: tf.Tensor(0.7226855937468964, shape=(), dtype=float64)\n",
      "0.48652735508024236\n",
      "iter: 0 Total loss: tf.Tensor(1.6568490580162232, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.771057001720525, shape=(), dtype=float64)\n",
      "iter: 186 Total loss: tf.Tensor(0.7226526062186607, shape=(), dtype=float64)\n",
      "0.48899668075610164\n",
      "iter: 0 Total loss: tf.Tensor(1.7584119089539825, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7748081304425999, shape=(), dtype=float64)\n",
      "iter: 180 Total loss: tf.Tensor(0.7223706093424368, shape=(), dtype=float64)\n",
      "0.49027558449857794\n",
      "iter: 0 Total loss: tf.Tensor(1.7616997248777342, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7726864671840216, shape=(), dtype=float64)\n",
      "iter: 183 Total loss: tf.Tensor(0.7224553257643781, shape=(), dtype=float64)\n",
      "0.48869004572301816\n",
      "iter: 0 Total loss: tf.Tensor(1.6701299927487325, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.776877441334008, shape=(), dtype=float64)\n",
      "iter: 185 Total loss: tf.Tensor(0.7229445152008834, shape=(), dtype=float64)\n",
      "0.4910169526589478\n",
      "iter: 0 Total loss: tf.Tensor(1.6647414614049667, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.779747586195011, shape=(), dtype=float64)\n",
      "iter: 188 Total loss: tf.Tensor(0.7231663299043471, shape=(), dtype=float64)\n",
      "0.4852766115351087\n",
      "iter: 0 Total loss: tf.Tensor(1.796816517153239, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7890143501994327, shape=(), dtype=float64)\n",
      "iter: 184 Total loss: tf.Tensor(0.7231636824650381, shape=(), dtype=float64)\n",
      "0.4880125924976849\n",
      "iter: 0 Total loss: tf.Tensor(1.670228806838657, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7820895426298118, shape=(), dtype=float64)\n",
      "iter: 177 Total loss: tf.Tensor(0.7242721868631484, shape=(), dtype=float64)\n",
      "0.48196671291159665\n"
     ]
    }
   ],
   "source": [
    "A = X_test\n",
    "A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "X = np.random.standard_normal((A.shape[0], embedding_dim))\n",
    "X_prime = X\n",
    "X_prime = tf.Variable(X_prime)\n",
    "\n",
    "Y_prime = Y_final\n",
    "\n",
    "[GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, X_grad_restrictions, Y_grad_restrictions] =  Multilearn_GLRM_Semisupervised_Test_Params(A_prime, X_prime, Y_prime)\n",
    "params[\"test_hyper_params\"] = [GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, X_grad_restrictions, Y_grad_restrictions]\n",
    "\n",
    "num_iterations=50000\n",
    "learning_rate=0.009\n",
    "results_log = []\n",
    "for i in range(0,10):\n",
    "    A = X_test\n",
    "    A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "    X = np.random.uniform(-1,1, (A.shape[0], embedding_dim))\n",
    "    X_prime = X\n",
    "    X_prime = tf.Variable(X_prime)\n",
    "\n",
    "    Y_prime = Y_final\n",
    "\n",
    "    result_val = Multi_Learn.predict(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, num_iterations, learning_rate)\n",
    "    val_pred = np.hstack((result_val[0], A_prime))\n",
    "    val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "    regress_val = np.matmul(val_pred, beta)\n",
    "    print(np.mean((Y_test - regress_val)**2))\n",
    "    results_log.append(np.mean((Y_test - regress_val)**2))\n",
    "\n",
    "params[\"test_error\"] = results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00f34e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './logs/Prostate_0.49_MSE.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs/Prostate_0.49_MSE.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(params, f)\n\u001b[1;32m      4\u001b[0m params\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './logs/Prostate_0.49_MSE.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    ".tolist()\n",
    "with open('./logs/Prostate_0.49_MSE.json', 'w') as f:\n",
    "    json.dump(params, f)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "beta\n",
    "<tf.Tensor: shape=(14, 1), dtype=float64, numpy=\n",
    "array([[-3.38347402e-03],\n",
    "       [ 6.39743435e-02],\n",
    "       [ 9.40026586e-02],\n",
    "       [ 1.21583354e-03],\n",
    "       [ 4.05847277e-01],\n",
    "       [ 4.73958481e-01],\n",
    "       [ 2.62763281e-01],\n",
    "       [-4.20586971e-02],\n",
    "       [ 1.75150903e-01],\n",
    "       [ 1.80748655e-01],\n",
    "       [-1.46233690e-03],\n",
    "       [ 2.20528090e-02],\n",
    "       [ 1.31451859e-01],\n",
    "       [ 2.43577201e+00]])>\n",
    "\n",
    "<tf.Tensor: shape=(14, 1), dtype=float64, numpy=\n",
    "array([[-3.12748490e-01],\n",
    "       [ 2.25695045e-01],\n",
    "       [ 2.33751380e-01],\n",
    "       [-2.30906162e-01],\n",
    "       [ 9.02321698e-02],\n",
    "       [ 4.54149462e-01],\n",
    "       [ 2.19087587e-01],\n",
    "       [-4.97710150e-02],\n",
    "       [ 1.59283026e-01],\n",
    "       [ 1.42314440e-01],\n",
    "       [-1.58384697e-03],\n",
    "       [ 2.94253544e-02],\n",
    "       [ 9.60553143e-02],\n",
    "       [ 2.44303569e+00]])>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33981bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41591a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.hstack((result_val[0], A_prime))\n",
    "val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "regress_val = np.matmul(val_pred, beta)\n",
    "np.mean((Y_test - regress_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions_val), confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c99ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "409/(409+200), 409/(409+857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "305/(305+133), 305/(305+961)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07698ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "2027/(2027+538), 2027/(2027+3343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_embedding = result[0][:, 1:embedding_dim+1]\n",
    "X_train_embedding = X_train_embedding.numpy()\n",
    "\n",
    "X_test_embedding = result_val[0].numpy()\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, Y_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(Y_train, pred_logistic), accuracy_score(Y_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, pred_logistic_val), confusion_matrix(Y_train, pred_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+236), 328/(328+938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "1565/(1565+650), 1565/(1565+3805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.Variable([1,1,1])\n",
    "tf.where(temp!=1).shape[0]\n",
    "# tf.where([True, False, False, True]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(result[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][3:10,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
