{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8541f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import semisupervised_params\n",
    "from supervised_embedding_params import Multilearn_GLRM_GetEmbedding\n",
    "from importlib import reload\n",
    "import Multi_Learn\n",
    "import generate_AXY\n",
    "import scipy.io as sio\n",
    "import pkg_resources\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d167f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(filename):\n",
    "    return sio.loadmat(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc9af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_range(label):\n",
    "    \"\"\"\n",
    "    Convert label to range\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    label: list of integers\n",
    "        must be in the form of [1, 1, ..., 1, 2, 2, ..., 2, ..., C, C, ..., C]\n",
    "        i.e. nondecreasing numbers starting from 1, each element is greater\n",
    "        than the previous element by at most 1\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a list of intergers with C + 1 elements, start with 0\n",
    "    the i-th element is number of elements in label that equals to i\n",
    "        \n",
    "    \"\"\"\n",
    "    res = [0]\n",
    "    assert label[0] == 1, 'label must start with 1'\n",
    "    for i in range(1, len(label)):\n",
    "        if label[i] == label[i-1]:\n",
    "            continue\n",
    "        if label[i] == label[i-1] + 1:\n",
    "            res.append(i)\n",
    "        else:\n",
    "            assert False,\\\n",
    "                ('label[{}] and label[{}] must be equal or two consecutive '\n",
    "                 'integers, got {} and {}').format(\n",
    "                     i-1, i, label[i-1], label[i]\n",
    "                 )\n",
    "    res.append(len(label))\n",
    "    return res\n",
    "\n",
    "def get_block_row(matrix, block_indices, row_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of rows from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 0-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of rows in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    if isinstance(block_indices, int):\n",
    "        block_indices = [block_indices]\n",
    "    # if isinstance(block_indices, (list, np.ndarray, np.generic))\n",
    "    ids = []\n",
    "    for i in block_indices:\n",
    "        ids = ids + list(range(row_range[i], row_range[i+1]))\n",
    "    return matrix[ids, :].copy()\n",
    "\n",
    "def get_block_col(matrix, block_indices, col_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 1-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of columns in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    assert matrix.shape[1] == col_range[-1]\n",
    "    return get_block_row(matrix.T, block_indices, col_range).T\n",
    "\n",
    "def get_block_col(matrix, block_indices, col_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 1-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of columns in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    assert matrix.shape[1] == col_range[-1]\n",
    "    return get_block_row(matrix.T, block_indices, col_range).T\n",
    "\n",
    "def randperm(n):\n",
    "    \"\"\"\n",
    "    get a random permutation of range(n)\n",
    "    \"\"\"\n",
    "    return np.random.permutation(list(range(n)))\n",
    "\n",
    "def normc(A):\n",
    "    \"\"\"\n",
    "    normalize each column of A to have norm2 = 1\n",
    "    \"\"\"\n",
    "    return A / np.tile(np.sqrt(np.sum(A*A, axis=0)), (A.shape[0], 1))\n",
    "def vec(A):\n",
    "    # TODO: rewrite docstrings\n",
    "    \"\"\"\n",
    "    * Syntax: `a = vec(A)`\n",
    "    * Vectorization of a matrix. This function is a built-in function in some\n",
    "    recent MATLAB version.\n",
    "    \"\"\"\n",
    "    return A.flatten('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d196c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fn = pkg_resources.resource_filename('data/myYaleB' + '.mat')\n",
    "vars_dict = load_mat('./DICTOL_python-master/dictol/data/AR_EigenFace' + '.mat')\n",
    "\n",
    "Y_train     = normc(vars_dict['tr_dat'])\n",
    "Y_test      = normc(vars_dict['tt_dat'])\n",
    "label_train = vec(vars_dict['trls']).astype(int)\n",
    "label_test  = vec(vars_dict['ttls']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f51344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 699, (300, 700), (300, 699))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train), len(label_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b94fa300",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = max(max(label_train), max(label_test))\n",
    "label_train\n",
    "one_hot_targets = np.eye(nb_classes)[np.array(label_train)-1]\n",
    "TRAIN = np.hstack((Y_train.T, one_hot_targets))\n",
    "np.random.shuffle(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96597f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "iter: 0 Total loss: tf.Tensor(277644.9114544433, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(235921.77088425605, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(196103.88947468944, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(159413.05984948933, shape=(), dtype=float64)\n",
      "iter: 400 Total loss: tf.Tensor(125630.44930489032, shape=(), dtype=float64)\n",
      "iter: 500 Total loss: tf.Tensor(94667.19701704876, shape=(), dtype=float64)\n",
      "iter: 600 Total loss: tf.Tensor(66490.24763861235, shape=(), dtype=float64)\n",
      "iter: 700 Total loss: tf.Tensor(41363.49671583501, shape=(), dtype=float64)\n",
      "iter: 800 Total loss: tf.Tensor(20003.815223216156, shape=(), dtype=float64)\n",
      "iter: 900 Total loss: tf.Tensor(6199.864102098612, shape=(), dtype=float64)\n",
      "iter: 961 Total loss: tf.Tensor(4696.202129511637, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(4693.935967130299, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(4005.9384296637286, shape=(), dtype=float64)\n",
      "iter: 191 Total loss: tf.Tensor(3791.2432911439896, shape=(), dtype=float64)\n",
      "epoch: 1\n",
      "iter: 0 Total loss: tf.Tensor(3789.3557631376084, shape=(), dtype=float64)\n",
      "iter: 7 Total loss: tf.Tensor(3564.939143381679, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(3556.664672085361, shape=(), dtype=float64)\n",
      "iter: 97 Total loss: tf.Tensor(3291.7691735337135, shape=(), dtype=float64)\n",
      "epoch: 2\n",
      "iter: 0 Total loss: tf.Tensor(3290.1418936968803, shape=(), dtype=float64)\n",
      "iter: 11 Total loss: tf.Tensor(3189.1031326561456, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(3185.584026382994, shape=(), dtype=float64)\n",
      "iter: 58 Total loss: tf.Tensor(3039.54561931187, shape=(), dtype=float64)\n",
      "epoch: 3\n",
      "iter: 0 Total loss: tf.Tensor(3038.0383209610563, shape=(), dtype=float64)\n",
      "iter: 9 Total loss: tf.Tensor(2983.9631920384086, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2980.7429432856197, shape=(), dtype=float64)\n",
      "iter: 42 Total loss: tf.Tensor(2885.167515499324, shape=(), dtype=float64)\n",
      "epoch: 4\n",
      "iter: 0 Total loss: tf.Tensor(2883.7489775157196, shape=(), dtype=float64)\n",
      "iter: 14 Total loss: tf.Tensor(2828.7672513071348, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2826.1838037270113, shape=(), dtype=float64)\n",
      "iter: 38 Total loss: tf.Tensor(2735.072487228127, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "reload(semisupervised_params)\n",
    "reload(Multi_Learn)\n",
    "reload(generate_AXY)\n",
    "from semisupervised_params import Multilearn_GLRM_Semisupervised\n",
    "from Multi_Learn import alternating_minimization, predict \n",
    "from generate_AXY import get_semisupervised_glrm_train_form\n",
    "\n",
    "embedding_dim = 50\n",
    "n_class = nb_classes\n",
    "\n",
    "A_prime, X_prime, Y_prime = get_semisupervised_glrm_train_form(TRAIN[:,:-nb_classes], TRAIN[:,-nb_classes:], nb_classes, embedding_dim)\n",
    "[GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions] = Multilearn_GLRM_Semisupervised(A_prime, X_prime, Y_prime, nb_classes)\n",
    "\n",
    "num_iterations=100000\n",
    "learning_rate=0.001\n",
    "result = alternating_minimization(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions, num_iterations, learning_rate, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14799cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985714285714286"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob = tf.nn.softmax(np.matmul(result[0], result[1][:,0:n_class])).numpy()\n",
    "label_train_shuffled =  np.argmax(TRAIN[:,-nb_classes:], axis=1)\n",
    "accuracy_score(label_train_shuffled, np.argmax(train_prob, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b960c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Total loss: tf.Tensor(1716.2372608609821, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(1198.6745200381458, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(864.6867040649054, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(629.3577836040645, shape=(), dtype=float64)\n",
      "iter: 400 Total loss: tf.Tensor(457.765422838966, shape=(), dtype=float64)\n",
      "iter: 500 Total loss: tf.Tensor(331.7029397096558, shape=(), dtype=float64)\n",
      "iter: 600 Total loss: tf.Tensor(239.15297889816216, shape=(), dtype=float64)\n",
      "iter: 700 Total loss: tf.Tensor(171.46262484671118, shape=(), dtype=float64)\n",
      "iter: 800 Total loss: tf.Tensor(122.21464188468781, shape=(), dtype=float64)\n",
      "iter: 900 Total loss: tf.Tensor(86.60354312482131, shape=(), dtype=float64)\n",
      "iter: 1000 Total loss: tf.Tensor(61.021552397273986, shape=(), dtype=float64)\n",
      "iter: 1100 Total loss: tf.Tensor(42.769910503301986, shape=(), dtype=float64)\n",
      "iter: 1200 Total loss: tf.Tensor(29.837939906268712, shape=(), dtype=float64)\n",
      "iter: 1300 Total loss: tf.Tensor(20.738125599781416, shape=(), dtype=float64)\n",
      "iter: 1400 Total loss: tf.Tensor(14.375564338514149, shape=(), dtype=float64)\n",
      "iter: 1500 Total loss: tf.Tensor(9.954264115887558, shape=(), dtype=float64)\n",
      "iter: 1600 Total loss: tf.Tensor(6.899350724102673, shape=(), dtype=float64)\n",
      "iter: 1700 Total loss: tf.Tensor(4.8000447839556095, shape=(), dtype=float64)\n",
      "iter: 1800 Total loss: tf.Tensor(3.3651700435372374, shape=(), dtype=float64)\n",
      "iter: 1900 Total loss: tf.Tensor(2.390854023416803, shape=(), dtype=float64)\n",
      "iter: 2000 Total loss: tf.Tensor(1.7326824376195755, shape=(), dtype=float64)\n",
      "iter: 2100 Total loss: tf.Tensor(1.2912155702393997, shape=(), dtype=float64)\n",
      "iter: 2200 Total loss: tf.Tensor(0.9977859511276106, shape=(), dtype=float64)\n",
      "iter: 2300 Total loss: tf.Tensor(0.8044977172329313, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "beta = result[1][1:,0:n_class]\n",
    "Y_final = result[1][1:embedding_dim+1,n_class:]\n",
    "\n",
    "A = Y_test.T\n",
    "A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "X = np.random.uniform(-1,1, (A.shape[0], embedding_dim))\n",
    "X_prime = X\n",
    "X_prime = tf.Variable(X_prime)\n",
    "\n",
    "Y_prime = Y_final\n",
    "X_regularization_loss_list, Y_regularization_loss_list = [], []\n",
    "\n",
    "GLRM_loss_list = [{\n",
    "    \"A_start_row\": 0,\n",
    "    \"A_end_row\" : A_prime.shape[0],\n",
    "    \"A_start_col\" : 0,\n",
    "    \"A_end_col\" : A_prime.shape[1],\n",
    "\n",
    "    \"X_start_row\": 0,\n",
    "    \"X_end_row\" : X_prime.shape[0],\n",
    "    \"X_start_col\" : 0,\n",
    "    \"X_end_col\" : X_prime.shape[1],\n",
    "\n",
    "    \"Y_start_row\": 0,\n",
    "    \"Y_end_row\" : Y_prime.shape[0],\n",
    "    \"Y_start_col\" : 0,\n",
    "    \"Y_end_col\" : Y_prime.shape[1],\n",
    "    \"weight\": 1,\n",
    "    \"loss\": 'MAE'\n",
    "}]\n",
    "\n",
    "X_regularization_loss_list = [\n",
    "    {\n",
    "        \"X_start_row\": 0,\n",
    "        \"X_end_row\" : X.shape[0],\n",
    "        \"X_start_col\" : 0,\n",
    "        \"X_end_col\" : X.shape[1],\n",
    "        \"penalty_type\" : 'L2',\n",
    "        \"alpha\": 0.001\n",
    "    },\n",
    "    {\n",
    "        \"X_start_row\": 0,\n",
    "        \"X_end_row\" : X.shape[0],\n",
    "        \"X_start_col\" : 0,\n",
    "        \"X_end_col\" : X.shape[1],\n",
    "        \"penalty_type\" : 'L1',\n",
    "        \"alpha\": 0.001\n",
    "    }\n",
    "]\n",
    "\n",
    "num_iterations=50000\n",
    "learning_rate=0.001\n",
    "result_val = predict(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, num_iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.hstack((result_val[0], A_prime))\n",
    "val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "val_pred = np.matmul(val_pred, beta)\n",
    "val_pred = tf.nn.softmax(val_pred).numpy()\n",
    "accuracy_score(np.array(label_test)-1, np.argmax(val_pred, axis=1))\n",
    "\n",
    "# accuracy_score(label_test, val_preds)\n",
    "\n",
    "# prob_val = np.exp(prob_val)/(1+np.exp(prob_val))\n",
    "# predictions_val = [1 if x >= 0.5 else 0 for x in prob_val]\n",
    "# accuracy_score(Y_test, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae76897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  5,  0,  0, 17, 17,  1, 76,  1,  6,  1,  2,  2,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3, 11,  3,  3,  3,  4,  4,  4,  4,  4,  6,\n",
       "        4,  5,  5,  5,  5, 16,  5,  5,  6,  6,  6, 39, 96,  6,  5,  7,  7,\n",
       "        7,  7,  7,  7,  7,  8,  8,  8,  8,  1,  8,  8, 14, 33, 36,  9, 96,\n",
       "        9,  5, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 96, 14, 14, 12,\n",
       "        7, 12,  7, 38, 12, 24,  4, 13,  4, 19,  4,  6, 13, 33,  4, 13, 13,\n",
       "       96, 14, 14, 15, 70, 15, 19, 18,  8,  8, 16, 16, 16, 35, 16, 35, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 18, 18, 58, 18, 18,  6,  5, 19, 19, 19,\n",
       "       19, 23, 19, 19, 20, 20, 20, 88, 20, 20, 20, 21, 21, 11,  0, 21, 21,\n",
       "       21, 35, 22, 35,  7, 22, 35,  5, 23, 36, 23, 23, 23,  6, 23, 24, 11,\n",
       "       14, 11, 63, 24, 24, 25, 25, 25, 25, 25, 25, 25, 41, 41, 41, 26, 26,\n",
       "       21, 26,  4, 11, 11, 11,  4, 27, 27, 28, 28, 28, 41, 28, 28, 28, 41,\n",
       "       11, 29, 29, 96, 14, 29, 36, 30, 36, 30,  5,  7,  5, 31, 31, 31, 31,\n",
       "       31, 31, 31, 32, 41, 32, 32, 32, 12, 32, 33, 33, 36,  9, 33, 14, 33,\n",
       "       34,  2, 34, 41, 34, 34, 34,  0, 35, 35, 39, 23, 35, 20, 36, 36, 36,\n",
       "       31,  5, 35,  5, 37, 37, 37, 44, 37,  6, 42, 36, 38, 58, 11, 38, 68,\n",
       "       21, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 39, 48, 98, 40, 41, 41,\n",
       "       41, 41,  5, 41,  5, 42, 42, 42, 40, 42,  6, 42, 43, 43, 43, 43, 76,\n",
       "       43, 43, 44, 44, 44,  9, 44,  6, 44, 53,  8, 53, 45, 53,  8, 20,  4,\n",
       "        4,  4, 39, 46,  6, 46, 37, 37, 37, 37, 80,  6,  1, 11, 48, 11, 39,\n",
       "       48, 35, 34, 55, 28, 49, 49, 49,  6, 49, 55, 58, 92, 92, 80, 85, 85,\n",
       "       51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53,\n",
       "       53, 53, 68, 68, 54, 54, 54, 55, 80, 35, 54, 55, 58, 55, 55, 80, 85,\n",
       "       85, 56, 56, 92, 55, 80, 85, 62, 57, 57, 10, 57, 57, 68, 57, 58, 58,\n",
       "       58, 58, 58, 71, 71, 59, 59, 59, 59, 59, 59, 59, 80, 60, 80, 92, 80,\n",
       "       60, 80, 61, 61, 75, 75, 53, 61, 61, 62, 62, 62, 84, 62,  6, 85, 80,\n",
       "       99, 99, 99, 80, 85, 85, 64, 64, 64, 58, 80, 85, 85, 71, 99, 92, 92,\n",
       "       80, 71, 71, 66, 66, 66, 58, 80, 66, 66, 67, 67, 67, 84, 96, 68, 67,\n",
       "       68, 68, 68, 57, 53, 68, 68, 75, 88, 75, 88,  1,  8, 69, 70, 70, 70,\n",
       "       88, 53, 70, 70, 71, 71, 71, 58, 80, 71, 80, 82, 82, 82, 82, 82, 98,\n",
       "       82, 62, 99, 22,  8, 80, 68, 73, 74, 74, 74, 74, 74, 74, 74, 75, 75,\n",
       "       75, 19, 75, 35, 75, 58, 76, 58, 97, 91, 97, 99, 99, 99, 58, 80, 99,\n",
       "       99, 58, 58, 58, 58, 80, 78, 85, 99, 99, 74, 81, 74, 79, 82, 80, 80,\n",
       "       80, 62, 80, 80, 80, 51, 51, 81, 81, 80, 68, 85, 88, 88, 88, 88, 88,\n",
       "       98, 82, 83, 83, 89, 55, 80, 83, 83, 58, 52, 52, 92, 52, 66, 71, 85,\n",
       "       58, 85, 85, 85, 85, 85, 58, 52, 58, 58, 80, 58, 86, 87, 87, 87, 85,\n",
       "       80, 85, 85, 99, 99, 99, 51, 99, 99, 99, 88, 88, 88, 88, 53, 89, 89,\n",
       "       82, 82, 82, 82, 82, 85, 82, 52, 91, 52, 55, 52, 71, 91, 92, 92, 92,\n",
       "       92, 80, 92, 92, 88, 88, 88, 88, 81, 35, 88, 58, 58, 58, 58, 80, 68,\n",
       "       84, 95, 95, 95, 58, 84, 85, 95, 58, 58, 58, 58, 80, 85, 82, 54, 33,\n",
       "       33, 97, 96, 68,  5, 98, 99, 74, 98, 82, 98, 98, 58, 58, 58, 58, 52,\n",
       "       91, 99])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(val_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "236a29d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
       "        4,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  7,  7,\n",
       "        7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n",
       "        9,  9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 12,\n",
       "       12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14,\n",
       "       14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19,\n",
       "       19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
       "       21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 24, 24,\n",
       "       24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26,\n",
       "       26, 26, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 29,\n",
       "       29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31,\n",
       "       31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33,\n",
       "       34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36,\n",
       "       36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38,\n",
       "       38, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 41, 41,\n",
       "       41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43,\n",
       "       43, 43, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 46,\n",
       "       46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48,\n",
       "       48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50,\n",
       "       51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53,\n",
       "       53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55,\n",
       "       55, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 58, 58,\n",
       "       58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60,\n",
       "       60, 60, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 63,\n",
       "       63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65,\n",
       "       65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67,\n",
       "       68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70,\n",
       "       70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72,\n",
       "       72, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 75, 75,\n",
       "       75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77,\n",
       "       77, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 80, 80,\n",
       "       80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82,\n",
       "       82, 82, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 85,\n",
       "       85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87,\n",
       "       87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89,\n",
       "       90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92,\n",
       "       92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94,\n",
       "       94, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 97, 97,\n",
       "       97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99,\n",
       "       99, 99])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_test),  val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions_val), confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c99ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "409/(409+200), 409/(409+857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "305/(305+133), 305/(305+961)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07698ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "2027/(2027+538), 2027/(2027+3343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_embedding = result[0][:, 1:embedding_dim+1]\n",
    "X_train_embedding = X_train_embedding.numpy()\n",
    "\n",
    "X_test_embedding = result_val[0].numpy()\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, Y_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(Y_train, pred_logistic), accuracy_score(Y_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, pred_logistic_val), confusion_matrix(Y_train, pred_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+236), 328/(328+938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "1565/(1565+650), 1565/(1565+3805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.Variable([1,1,1])\n",
    "tf.where(temp!=1).shape[0]\n",
    "# tf.where([True, False, False, True]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(result[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][3:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7460b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.09003057, 0.24472848, 0.665241  ], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_info = Y_regularization_loss_list[2]\n",
    "\n",
    "# A_00, A_10, A_01, A_11 = loss_info['A_start_row'], loss_info['A_end_row'], loss_info['A_start_col'], loss_info['A_end_col']\n",
    "X_00, X_10, X_01, X_11 = loss_info['X_start_row'], loss_info['X_end_row'], loss_info['X_start_col'], loss_info['X_end_col']\n",
    "# Y_00, Y_10, Y_01, Y_11 = loss_info['Y_start_row'], loss_info['Y_end_row'], loss_info['Y_start_col'], loss_info['Y_end_col']\n",
    "\n",
    "\n",
    "# A_prime[A_00:A_10, A_01:A_11]\n",
    "# X_prime[X_00:X_10, X_01:X_11]\n",
    "# Y_prime[Y_00:Y_10, Y_01:Y_11]\n",
    "Y_prime[X_00:X_10, X_01:X_11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1.\n",
    "a = 0.\n",
    "current_min = 1.\n",
    "current_max = 38.\n",
    "\n",
    "def scale_class(val):\n",
    "    return (b-a)*(val-current_min)/(current_max-current_min)\n",
    "\n",
    "def scale_inv(val):\n",
    "    return val*(current_max-current_min) / (b-a) +current_min\n",
    "label_train_arr = np.array(label_train).reshape(-1,1)\n",
    "vfunc = np.vectorize(scale_class)\n",
    "label_train_arr_scaled = vfunc(label_train_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
