{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8541f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import MultiLearn_GLRM\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d51f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Experiments/ESLR/prostate/prostate.data', delimiter='\\t', index_col=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "mask_train = df.pop('train')\n",
    "df_y = df.pop('lpsa')\n",
    "\n",
    "X_train = df[mask_train == 'T']\n",
    "Y_train = df_y[mask_train == 'T']\n",
    "Y_train = np.array(Y_train).reshape(-1,1)\n",
    "\n",
    "\n",
    "X_test = df[mask_train != 'T']\n",
    "Y_test = df_y[mask_train != 'T']\n",
    "Y_test = np.array(Y_test).reshape(-1,1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "params = {\n",
    "    \"train_hyper_params\": None,\n",
    "    \"test_hyper_params\": None,\n",
    "    \"beta\": None,\n",
    "    \"embedding_matrix\": None,\n",
    "    \"train_error\": None,\n",
    "    \"test_error\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96597f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "iter: 386 Total loss: tf.Tensor(4.573163934808955, shape=(), dtype=float64)\n",
      "iter: 59 Total loss: tf.Tensor(1.7669164500028334, shape=(), dtype=float64)\n",
      "epoch: 1\n",
      "iter: 155 Total loss: tf.Tensor(0.9104548625682602, shape=(), dtype=float64)\n",
      "iter: 10 Total loss: tf.Tensor(0.8389521489138734, shape=(), dtype=float64)\n",
      "epoch: 2\n",
      "iter: 55 Total loss: tf.Tensor(0.785934297951629, shape=(), dtype=float64)\n",
      "iter: 5 Total loss: tf.Tensor(0.7827244209536408, shape=(), dtype=float64)\n",
      "epoch: 3\n",
      "iter: 259 Total loss: tf.Tensor(0.7527138291528178, shape=(), dtype=float64)\n",
      "iter: 116 Total loss: tf.Tensor(0.7514508145929245, shape=(), dtype=float64)\n",
      "epoch: 4\n",
      "iter: 367 Total loss: tf.Tensor(0.7495283015307668, shape=(), dtype=float64)\n",
      "iter: 3 Total loss: tf.Tensor(0.7508748266839278, shape=(), dtype=float64)\n",
      "epoch: 4 Total loss: tf.Tensor(0.7510585601086077, shape=(), dtype=float64)\n",
      "Final loss: tf.Tensor(0.7510585601086077, shape=(), dtype=float64) best loss: tf.Tensor(0.7510585601086077, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "reload(MultiLearn_GLRM)\n",
    "from MultiLearn_GLRM import Multi_Learn, generate_AXY\n",
    "from MultiLearn_GLRM.Params.semisupervised_params import Multilearn_GLRM_Semisupervised_Train_Params, Multilearn_GLRM_Semisupervised_Test_Params\n",
    "\n",
    "embedding_dim = 5\n",
    "n_class = 1\n",
    "\n",
    "A_prime, X_prime, Y_prime = generate_AXY.get_semisupervised_glrm_train_form(X_train, Y_train, n_class, embedding_dim)\n",
    "[GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions] = Multilearn_GLRM_Semisupervised_Train_Params(A_prime, X_prime, Y_prime, n_class)\n",
    "\n",
    "params[\"train_hyper_params\"] = [GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions]\n",
    "\n",
    "num_iterations=100000\n",
    "learning_rate=0.01\n",
    "result = Multi_Learn.alternating_minimization(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions, num_iterations, learning_rate, n_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d4c693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49761031816784335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = result[1][1:,0:n_class]\n",
    "Y_final = result[1][1:embedding_dim+1,n_class:]\n",
    "params[\"beta\"] = beta\n",
    "params[\"embedding_matrix\"] = Y_final\n",
    "\n",
    "res = np.matmul(result[0], result[1][:,0:n_class])\n",
    "params[\"train_error\"] = np.mean((Y_train - res)**2)\n",
    "params[\"train_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558196dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = np.matmul(result[0], result[1][:,0:n_class])\n",
    "# np.mean((Y_train - res)**2)\n",
    "# 0.4495674496068231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6761625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, Y_train.shape[0]):\n",
    "    print(Y_train[i], res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918b960c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Total loss: tf.Tensor(1.529842555045751, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7898710020225588, shape=(), dtype=float64)\n",
      "iter: 119 Total loss: tf.Tensor(0.7636602785599883, shape=(), dtype=float64)\n",
      "0.490090077931291\n",
      "iter: 0 Total loss: tf.Tensor(1.5327151629238407, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7859905077684408, shape=(), dtype=float64)\n",
      "iter: 122 Total loss: tf.Tensor(0.759476668879253, shape=(), dtype=float64)\n",
      "0.49005512554692743\n",
      "iter: 0 Total loss: tf.Tensor(1.5593074435602872, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7898472921857284, shape=(), dtype=float64)\n",
      "iter: 123 Total loss: tf.Tensor(0.7609252171727972, shape=(), dtype=float64)\n",
      "0.4900664107714302\n",
      "iter: 0 Total loss: tf.Tensor(1.5613645877080988, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7921973851821976, shape=(), dtype=float64)\n",
      "iter: 128 Total loss: tf.Tensor(0.7578234800024003, shape=(), dtype=float64)\n",
      "0.49005951285335486\n",
      "iter: 0 Total loss: tf.Tensor(1.5810166063967148, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7956350893744871, shape=(), dtype=float64)\n",
      "iter: 125 Total loss: tf.Tensor(0.7590157331521297, shape=(), dtype=float64)\n",
      "0.4900653842493022\n",
      "iter: 0 Total loss: tf.Tensor(1.6702022204964782, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7988157094692713, shape=(), dtype=float64)\n",
      "iter: 127 Total loss: tf.Tensor(0.7585075061978925, shape=(), dtype=float64)\n",
      "0.4900767517886954\n",
      "iter: 0 Total loss: tf.Tensor(1.5583813835810072, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7866098182803541, shape=(), dtype=float64)\n",
      "iter: 121 Total loss: tf.Tensor(0.7602860993103916, shape=(), dtype=float64)\n",
      "0.4900333755287437\n",
      "iter: 0 Total loss: tf.Tensor(1.6050514869441037, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7913464559087113, shape=(), dtype=float64)\n",
      "iter: 129 Total loss: tf.Tensor(0.7577838114254117, shape=(), dtype=float64)\n",
      "0.4900765831061479\n",
      "iter: 0 Total loss: tf.Tensor(1.576373790754726, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7921547798529444, shape=(), dtype=float64)\n",
      "iter: 127 Total loss: tf.Tensor(0.7582813605839238, shape=(), dtype=float64)\n",
      "0.49007148033036924\n",
      "iter: 0 Total loss: tf.Tensor(1.5271184335320598, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(0.7816345983582759, shape=(), dtype=float64)\n",
      "iter: 122 Total loss: tf.Tensor(0.7584836138700675, shape=(), dtype=float64)\n",
      "0.49007169287003804\n"
     ]
    }
   ],
   "source": [
    "A = X_test\n",
    "A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "X = np.random.standard_normal((A.shape[0], embedding_dim))\n",
    "X_prime = X\n",
    "X_prime = tf.Variable(X_prime)\n",
    "\n",
    "Y_prime = Y_final\n",
    "\n",
    "[GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, X_grad_restrictions, Y_grad_restrictions] =  Multilearn_GLRM_Semisupervised_Test_Params(A_prime, X_prime, Y_prime)\n",
    "params[\"test_hyper_params\"] = [GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, X_grad_restrictions, Y_grad_restrictions]\n",
    "\n",
    "num_iterations=50000\n",
    "learning_rate=0.009\n",
    "results_log = []\n",
    "for i in range(0,10):\n",
    "    A = X_test\n",
    "    A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "    X = np.random.uniform(-1,1, (A.shape[0], embedding_dim))\n",
    "    X_prime = X\n",
    "    X_prime = tf.Variable(X_prime)\n",
    "\n",
    "    Y_prime = Y_final\n",
    "\n",
    "    result_val = Multi_Learn.predict(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, num_iterations, learning_rate)\n",
    "    val_pred = np.hstack((result_val[0], A_prime))\n",
    "    val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "    regress_val = np.matmul(val_pred, beta)\n",
    "    print(np.mean((Y_test - regress_val)**2))\n",
    "    results_log.append(np.mean((Y_test - regress_val)**2))\n",
    "\n",
    "params[\"test_error\"] = results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00f34e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './logs/Prostate_0.49_MSE.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs/Prostate_0.49_MSE.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(params, f)\n\u001b[1;32m      4\u001b[0m params\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './logs/Prostate_0.49_MSE.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    ".tolist()\n",
    "with open('./logs/Prostate_0.49_MSE.json', 'w') as f:\n",
    "    json.dump(params, f)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "beta\n",
    "<tf.Tensor: shape=(14, 1), dtype=float64, numpy=\n",
    "array([[-3.38347402e-03],\n",
    "       [ 6.39743435e-02],\n",
    "       [ 9.40026586e-02],\n",
    "       [ 1.21583354e-03],\n",
    "       [ 4.05847277e-01],\n",
    "       [ 4.73958481e-01],\n",
    "       [ 2.62763281e-01],\n",
    "       [-4.20586971e-02],\n",
    "       [ 1.75150903e-01],\n",
    "       [ 1.80748655e-01],\n",
    "       [-1.46233690e-03],\n",
    "       [ 2.20528090e-02],\n",
    "       [ 1.31451859e-01],\n",
    "       [ 2.43577201e+00]])>\n",
    "\n",
    "<tf.Tensor: shape=(14, 1), dtype=float64, numpy=\n",
    "array([[-3.12748490e-01],\n",
    "       [ 2.25695045e-01],\n",
    "       [ 2.33751380e-01],\n",
    "       [-2.30906162e-01],\n",
    "       [ 9.02321698e-02],\n",
    "       [ 4.54149462e-01],\n",
    "       [ 2.19087587e-01],\n",
    "       [-4.97710150e-02],\n",
    "       [ 1.59283026e-01],\n",
    "       [ 1.42314440e-01],\n",
    "       [-1.58384697e-03],\n",
    "       [ 2.94253544e-02],\n",
    "       [ 9.60553143e-02],\n",
    "       [ 2.44303569e+00]])>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33981bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41591a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.hstack((result_val[0], A_prime))\n",
    "val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "regress_val = np.matmul(val_pred, beta)\n",
    "np.mean((Y_test - regress_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions_val), confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c99ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "409/(409+200), 409/(409+857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "305/(305+133), 305/(305+961)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07698ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "2027/(2027+538), 2027/(2027+3343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_embedding = result[0][:, 1:embedding_dim+1]\n",
    "X_train_embedding = X_train_embedding.numpy()\n",
    "\n",
    "X_test_embedding = result_val[0].numpy()\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, Y_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(Y_train, pred_logistic), accuracy_score(Y_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, pred_logistic_val), confusion_matrix(Y_train, pred_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+236), 328/(328+938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "1565/(1565+650), 1565/(1565+3805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.Variable([1,1,1])\n",
    "tf.where(temp!=1).shape[0]\n",
    "# tf.where([True, False, False, True]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(result[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][3:10,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
