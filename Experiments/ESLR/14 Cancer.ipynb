{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from importlib import reload\n",
    "import json\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18b8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import MultiLearn_GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bf28c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./cancer/xtrain.data', sep='\\s+', header=None)\n",
    "df_label_train = pd.read_csv('./cancer/xtrain_label.data', sep='\\s+', header=None)\n",
    "df_test = pd.read_csv('./cancer/xtest.data', sep='\\s+', header=None)\n",
    "df_label_test = pd.read_csv('./cancer/xtest_label.data', sep='\\s+', header=None)\n",
    "\n",
    "df_train.loc[-1] = df_label_train.loc[0].to_list()\n",
    "df_train.index = df_train.index + 1  \n",
    "df_train = df_train.sort_index()\n",
    "df_train = df_train.T\n",
    "\n",
    "df_test.loc[-1] = df_label_test.loc[0].to_list()\n",
    "df_test.index = df_test.index + 1  \n",
    "df_test = df_test.sort_index()\n",
    "df_test = df_test.T\n",
    "\n",
    "\n",
    "X_train = df_train.drop(columns=[0])\n",
    "Y_train = df_train[0]\n",
    "Y_train = np.array(Y_train, dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "X_test = df_test.drop(columns=[0])\n",
    "Y_test = df_test[0]\n",
    "Y_test = np.array(Y_test, dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"train_hyper_params\": None,\n",
    "    \"test_hyper_params\": None,\n",
    "    \"beta\": None,\n",
    "    \"embedding_matrix\": None,\n",
    "    \"train_error\": None,\n",
    "    \"test_error\": None,\n",
    "    \"embedding_dim\": None,\n",
    "    \"predictor_scaling_parmas\": None,\n",
    "    \"target_scaling_parmas\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "596a5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=144)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "n_class = max(max(Y_train), max(Y_test))[0]\n",
    "\n",
    "one_hot_targets = np.eye(n_class)[Y_train.reshape(-1,)-1]\n",
    "Train = np.hstack((X_train_pca, one_hot_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b13c87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 158)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84527605",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"predictor_scaling_parmas\"] =  {\n",
    "    \"mean\" : scaler.mean_.tolist(),\n",
    "    \"var\" : scaler.mean_.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96597f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "iter: 0 Total loss: tf.Tensor(184.46474863733135, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=13.770082555309555>, <tf.Tensor: shape=(), dtype=float64, numpy=121.0170630334533>]\n",
      "iter: 5 Total loss: tf.Tensor(167.99011018350282, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(167.59401771604348, shape=(), dtype=float64)\n",
      "iter: 6 Total loss: tf.Tensor(102.96721050529024, shape=(), dtype=float64)\n",
      "epoch: 1\n",
      "iter: 0 Total loss: tf.Tensor(100.79053489402534, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=13.730577190649857>, <tf.Tensor: shape=(), dtype=float64, numpy=94.53722614243927>]\n",
      "iter: 11 Total loss: tf.Tensor(78.10472769147424, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(77.83287721998386, shape=(), dtype=float64)\n",
      "iter: 6 Total loss: tf.Tensor(65.99857643690643, shape=(), dtype=float64)\n",
      "epoch: 2\n",
      "iter: 0 Total loss: tf.Tensor(64.05095898663163, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=10.86156014425721>, <tf.Tensor: shape=(), dtype=float64, numpy=52.55833218499381>]\n",
      "iter: 4 Total loss: tf.Tensor(60.600781193293464, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(60.4401615460022, shape=(), dtype=float64)\n",
      "iter: 5 Total loss: tf.Tensor(58.11391058516815, shape=(), dtype=float64)\n",
      "epoch: 3\n",
      "iter: 0 Total loss: tf.Tensor(57.932790579911995, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=9.986341445879184>, <tf.Tensor: shape=(), dtype=float64, numpy=47.289280037442275>]\n",
      "iter: 3 Total loss: tf.Tensor(56.87213908458379, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(56.80215577618886, shape=(), dtype=float64)\n",
      "iter: 7 Total loss: tf.Tensor(55.06573838392977, shape=(), dtype=float64)\n",
      "epoch: 4\n",
      "iter: 0 Total loss: tf.Tensor(54.94270528241222, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=8.060022441233581>, <tf.Tensor: shape=(), dtype=float64, numpy=45.85676872396533>]\n",
      "iter: 1 Total loss: tf.Tensor(54.758306309981556, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(54.425294210062916, shape=(), dtype=float64)\n",
      "iter: 9 Total loss: tf.Tensor(53.66456736945378, shape=(), dtype=float64)\n",
      "epoch: 5\n",
      "iter: 0 Total loss: tf.Tensor(53.51060362454392, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=5.8390761220268494>, <tf.Tensor: shape=(), dtype=float64, numpy=45.41179383712982>]\n",
      "iter: 1 Total loss: tf.Tensor(53.32270021735302, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(53.13815451289116, shape=(), dtype=float64)\n",
      "iter: 10 Total loss: tf.Tensor(52.63082549410968, shape=(), dtype=float64)\n",
      "epoch: 6\n",
      "iter: 0 Total loss: tf.Tensor(52.77829869625933, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=7.331167306455004>, <tf.Tensor: shape=(), dtype=float64, numpy=45.16871091498617>]\n",
      "iter: 1 Total loss: tf.Tensor(52.63508749945809, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(52.520724708474106, shape=(), dtype=float64)\n",
      "iter: 11 Total loss: tf.Tensor(52.2498159679096, shape=(), dtype=float64)\n",
      "epoch: 7\n",
      "iter: 0 Total loss: tf.Tensor(52.05979457726878, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=4.67522171002401>, <tf.Tensor: shape=(), dtype=float64, numpy=45.03421087739724>]\n",
      "iter: 1 Total loss: tf.Tensor(51.953129561805774, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(51.87954185115315, shape=(), dtype=float64)\n",
      "iter: 13 Total loss: tf.Tensor(51.85621990641602, shape=(), dtype=float64)\n",
      "epoch: 8\n",
      "iter: 0 Total loss: tf.Tensor(51.66502340635189, shape=(), dtype=float64) [<tf.Tensor: shape=(), dtype=float64, numpy=3.7937175601914706>, <tf.Tensor: shape=(), dtype=float64, numpy=44.94901994442726>]\n",
      "iter: 1 Total loss: tf.Tensor(51.58838343614202, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(51.53766585166328, shape=(), dtype=float64)\n",
      "iter: 16 Total loss: tf.Tensor(51.35944840894561, shape=(), dtype=float64)\n",
      "Final loss: tf.Tensor(51.61559818957022, shape=(), dtype=float64) best loss: tf.Tensor(51.61559818957022, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "reload(MultiLearn_GLRM)\n",
    "from MultiLearn_GLRM import Multi_Learn, generate_AXY\n",
    "from MultiLearn_GLRM.Params.semisupervised_params import Multilearn_GLRM_Semisupervised_Train_Params, Multilearn_GLRM_Semisupervised_Test_Params\n",
    "\n",
    "embedding_dim = 10\n",
    "params[\"embedding_dim\"] = embedding_dim\n",
    "\n",
    "n_class = n_class\n",
    "\n",
    "A_prime, X_prime, Y_prime = generate_AXY.get_semisupervised_glrm_train_form(Train[:,:-n_class], Train[:,-n_class:], n_class, embedding_dim)\n",
    "GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions = Multilearn_GLRM_Semisupervised_Train_Params(A_prime, X_prime, Y_prime, n_class)\n",
    "\n",
    "params[\"train_hyper_params\"] = [GLRM_loss_list, X_regulariation_list, Y_regulariation_list]\n",
    "\n",
    "num_iterations=100\n",
    "learning_rate=0.5\n",
    "result = Multi_Learn.alternating_minimization(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions, num_iterations, learning_rate, n_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c229acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11805555555555555"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = result[1][1:,0:n_class]\n",
    "Y_final = result[1][1:embedding_dim+1,n_class:]\n",
    "params[\"beta\"] = beta.numpy().tolist()\n",
    "params[\"embedding_matrix\"] = Y_final.numpy().tolist()\n",
    "\n",
    "train_prob = tf.nn.softmax(np.matmul(result[0], result[1][:,0:n_class])).numpy()\n",
    "label_train_shuffled =  np.argmax(Train[:,-n_class:], axis=1)\n",
    "params[\"train_accuracy\"] = accuracy_score(label_train_shuffled, np.argmax(train_prob, axis=1))\n",
    "params[\"train_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22f1319d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e858e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  1,  1,  2,  1,  1,  2,  5,  2,  1,  1,  6,  8,  2,  8,  6,\n",
       "        2,  2,  1,  1,  6,  2, 13,  6,  2,  8,  1, 11, 11,  2,  2,  6,  4,\n",
       "        4,  4,  1,  4,  4,  4,  7,  4,  1,  6,  9,  6,  7,  4,  2,  2,  2,\n",
       "        2,  7,  1,  2,  7,  1,  6,  4,  1,  2,  2,  1,  4,  5,  5,  2,  5,\n",
       "        6,  5,  3,  4,  5,  6, 11,  4,  5,  4,  8,  8,  4,  5,  4,  5,  5,\n",
       "        4,  4,  4, 11,  5,  4,  4,  6,  4,  4, 11,  1,  6, 13,  2, 13, 11,\n",
       "        6,  1,  6,  2,  1,  5,  4,  1,  4,  2,  2,  6,  4,  1,  5, 11,  6,\n",
       "        8,  2,  2,  4,  5,  2,  5,  2,  2,  6,  1,  6, 12,  2,  5,  6,  5,\n",
       "        6,  4,  4,  5,  2,  6,  8,  4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(train_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558196dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = np.matmul(result[0], result[1][:,0:n_class])\n",
    "# np.mean((Y_train - res)**2)\n",
    "# 0.4495674496068231\n",
    "\n",
    "# res = np.matmul(result[0], result[1][:,0:n_class])\n",
    "# np.mean((Y_train - res)**2)\n",
    "# 0.4011543372347976\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<tf.Tensor: shape=(11, 1), dtype=float64, numpy=\n",
    "array([[-0.02956712],\n",
    "       [-0.43500185],\n",
    "       [ 0.46663761],\n",
    "       [ 0.28479513],\n",
    "       [-0.04591487],\n",
    "       [ 0.22732162],\n",
    "       [ 0.19878154],\n",
    "       [-0.21300145],\n",
    "       [ 0.0071286 ],\n",
    "       [ 0.11102323],\n",
    "       [-0.00936144]])>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6761625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, Y_train.shape[0]):\n",
    "    print(Y_train[i], res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(MultiLearn_GLRM)\n",
    "from MultiLearn_GLRM import Multi_Learn, generate_AXY\n",
    "from MultiLearn_GLRM.Params.semisupervised_params import Multilearn_GLRM_Semisupervised_Train_Params, Multilearn_GLRM_Semisupervised_Test_Params\n",
    "\n",
    "A = X_test\n",
    "A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "X = np.random.standard_normal((A.shape[0], embedding_dim))\n",
    "X_prime = X\n",
    "X_prime = tf.Variable(X_prime)\n",
    "\n",
    "Y_prime = Y_final\n",
    "\n",
    "GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, X_grad_restrictions, Y_grad_restrictions =  Multilearn_GLRM_Semisupervised_Test_Params(A_prime, X_prime, Y_prime)\n",
    "params[\"test_hyper_params\"] = [GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list]\n",
    "\n",
    "num_iterations=10000\n",
    "learning_rate=0.004\n",
    "results_log = []\n",
    "for i in range(0,10):\n",
    "    A = X_test\n",
    "    A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "    X = np.random.uniform(-1,1, (A.shape[0], embedding_dim))\n",
    "    X_prime = X\n",
    "    X_prime = tf.Variable(X_prime)\n",
    "\n",
    "    Y_prime = Y_final\n",
    "\n",
    "    result_val = Multi_Learn.predict(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, num_iterations, learning_rate)\n",
    "    val_pred = np.hstack((result_val[0], A_prime))\n",
    "    val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "    val_pred = np.matmul(val_pred, beta)\n",
    "    val_pred = tf.nn.softmax(val_pred).numpy()\n",
    "    accuracy = accuracy_score(np.array(label_test)-1, np.argmax(val_pred, axis=1))\n",
    "\n",
    "    print(accuracy)\n",
    "    results_log.append(accuracy)\n",
    "\n",
    "\n",
    "params[\"accuracy\"] = results_log\n",
    "\n",
    "# with open('./logs/Prostate_'+ str(round(np.mean(results_log),5))+'_MSE.json', 'w') as f:\n",
    "#     f.write(json.dumps(params, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc1d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f25389",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.hstack((result_val[0], A_prime))\n",
    "val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "regress_val = np.matmul(val_pred, beta)\n",
    "np.mean((scaler2.inverse_transform(Y_test) - scaler2.inverse_transform(regress_val))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions_val), confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c99ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "409/(409+200), 409/(409+857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "305/(305+133), 305/(305+961)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07698ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "2027/(2027+538), 2027/(2027+3343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_embedding = result[0][:, 1:embedding_dim+1]\n",
    "X_train_embedding = X_train_embedding.numpy()\n",
    "\n",
    "X_test_embedding = result_val[0].numpy()\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, Y_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(Y_train, pred_logistic), accuracy_score(Y_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, pred_logistic_val), confusion_matrix(Y_train, pred_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+236), 328/(328+938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "1565/(1565+650), 1565/(1565+3805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.Variable([1,1,1])\n",
    "tf.where(temp!=1).shape[0]\n",
    "# tf.where([True, False, False, True]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(result[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][3:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'beta' in params.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
