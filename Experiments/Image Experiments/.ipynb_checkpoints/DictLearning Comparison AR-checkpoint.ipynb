{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8541f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from importlib import reload\n",
    "import scipy.io as sio\n",
    "import pkg_resources\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffffa7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import MultiLearn_GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc9af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(filename):\n",
    "    return sio.loadmat(filename)\n",
    "\n",
    "def label_to_range(label):\n",
    "    \"\"\"\n",
    "    Convert label to range\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    label: list of integers\n",
    "        must be in the form of [1, 1, ..., 1, 2, 2, ..., 2, ..., C, C, ..., C]\n",
    "        i.e. nondecreasing numbers starting from 1, each element is greater\n",
    "        than the previous element by at most 1\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a list of intergers with C + 1 elements, start with 0\n",
    "    the i-th element is number of elements in label that equals to i\n",
    "        \n",
    "    \"\"\"\n",
    "    res = [0]\n",
    "    assert label[0] == 1, 'label must start with 1'\n",
    "    for i in range(1, len(label)):\n",
    "        if label[i] == label[i-1]:\n",
    "            continue\n",
    "        if label[i] == label[i-1] + 1:\n",
    "            res.append(i)\n",
    "        else:\n",
    "            assert False,\\\n",
    "                ('label[{}] and label[{}] must be equal or two consecutive '\n",
    "                 'integers, got {} and {}').format(\n",
    "                     i-1, i, label[i-1], label[i]\n",
    "                 )\n",
    "    res.append(len(label))\n",
    "    return res\n",
    "\n",
    "def get_block_row(matrix, block_indices, row_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of rows from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 0-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of rows in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    if isinstance(block_indices, int):\n",
    "        block_indices = [block_indices]\n",
    "    # if isinstance(block_indices, (list, np.ndarray, np.generic))\n",
    "    ids = []\n",
    "    for i in block_indices:\n",
    "        ids = ids + list(range(row_range[i], row_range[i+1]))\n",
    "    return matrix[ids, :].copy()\n",
    "\n",
    "def get_block_col(matrix, block_indices, col_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 1-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of columns in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    assert matrix.shape[1] == col_range[-1]\n",
    "    return get_block_row(matrix.T, block_indices, col_range).T\n",
    "\n",
    "def get_block_col(matrix, block_indices, col_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 1-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of columns in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    assert matrix.shape[1] == col_range[-1]\n",
    "    return get_block_row(matrix.T, block_indices, col_range).T\n",
    "\n",
    "def randperm(n):\n",
    "    \"\"\"\n",
    "    get a random permutation of range(n)\n",
    "    \"\"\"\n",
    "    return np.random.permutation(list(range(n)))\n",
    "\n",
    "def normc(A):\n",
    "    \"\"\"\n",
    "    normalize each column of A to have norm2 = 1\n",
    "    \"\"\"\n",
    "    return A / np.tile(np.sqrt(np.sum(A*A, axis=0)), (A.shape[0], 1))\n",
    "def vec(A):\n",
    "    # TODO: rewrite docstrings\n",
    "    \"\"\"\n",
    "    * Syntax: `a = vec(A)`\n",
    "    * Vectorization of a matrix. This function is a built-in function in some\n",
    "    recent MATLAB version.\n",
    "    \"\"\"\n",
    "    return A.flatten('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d196c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fn = pkg_resources.resource_filename('data/myYaleB' + '.mat')\n",
    "vars_dict = load_mat('./DICTOL_python-master/dictol/data/AR_EigenFace' + '.mat')\n",
    "\n",
    "Y_train     = normc(vars_dict['tr_dat'])\n",
    "Y_test      = normc(vars_dict['tt_dat'])\n",
    "label_train = vec(vars_dict['trls']).astype(int)\n",
    "label_test  = vec(vars_dict['ttls']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f51344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 699, (300, 700), (300, 699))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train), len(label_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94fa300",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = max(max(label_train), max(label_test))\n",
    "label_train\n",
    "one_hot_targets = np.eye(nb_classes)[np.array(label_train)-1]\n",
    "TRAIN = np.hstack((Y_train.T, one_hot_targets))\n",
    "np.random.shuffle(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96597f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "epoch: 0\n",
      "iter: 0 Total loss: tf.Tensor(278050.950695167, shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 20:22:15.444931: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-01 20:22:15.445100: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 Total loss: tf.Tensor(236135.16184908355, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(196179.28542747494, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(159324.81252822842, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "reload(MultiLearn_GLRM)\n",
    "from MultiLearn_GLRM import Multi_Learn, generate_AXY\n",
    "from MultiLearn_GLRM.Params.semisupervised_params import Multilearn_GLRM_Semisupervised\n",
    "\n",
    "embedding_dim = 50\n",
    "n_class = nb_classes\n",
    "\n",
    "A_prime, X_prime, Y_prime = generate_AXY.get_semisupervised_glrm_train_form(TRAIN[:,:-nb_classes], TRAIN[:,-nb_classes:], n_class, embedding_dim)\n",
    "[GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions] = Multilearn_GLRM_Semisupervised(A_prime, X_prime, Y_prime, n_class)\n",
    "\n",
    "num_iterations=100000\n",
    "learning_rate=0.001\n",
    "result = Multi_Learn.alternating_minimization(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions, num_iterations, learning_rate, n_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14799cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985714285714286"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob = tf.nn.softmax(np.matmul(result[0], result[1][:,0:n_class])).numpy()\n",
    "label_train_shuffled =  np.argmax(TRAIN[:,-nb_classes:], axis=1)\n",
    "accuracy_score(label_train_shuffled, np.argmax(train_prob, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "918b960c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Total loss: tf.Tensor(335935.61339478457, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(279491.02691909164, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(230123.26674897555, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(186248.67286096833, shape=(), dtype=float64)\n",
      "iter: 400 Total loss: tf.Tensor(146795.61102243233, shape=(), dtype=float64)\n",
      "iter: 500 Total loss: tf.Tensor(111296.60391620116, shape=(), dtype=float64)\n",
      "iter: 600 Total loss: tf.Tensor(79645.2832556039, shape=(), dtype=float64)\n",
      "iter: 700 Total loss: tf.Tensor(52045.2642767978, shape=(), dtype=float64)\n",
      "iter: 800 Total loss: tf.Tensor(28906.72087674717, shape=(), dtype=float64)\n",
      "iter: 900 Total loss: tf.Tensor(11935.787107034132, shape=(), dtype=float64)\n",
      "iter: 1000 Total loss: tf.Tensor(4733.638349540374, shape=(), dtype=float64)\n",
      "iter: 1100 Total loss: tf.Tensor(3529.031375611661, shape=(), dtype=float64)\n",
      "iter: 1148 Total loss: tf.Tensor(3422.7373583547756, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "beta = result[1][1:,0:n_class]\n",
    "Y_final = result[1][1:embedding_dim+1,n_class:]\n",
    "\n",
    "A = Y_test.T\n",
    "A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "X = np.random.uniform(-1,1, (A.shape[0], embedding_dim))\n",
    "X_prime = X\n",
    "X_prime = tf.Variable(X_prime)\n",
    "\n",
    "Y_prime = Y_final\n",
    "X_regularization_loss_list, Y_regularization_loss_list = [], []\n",
    "\n",
    "GLRM_loss_list = [{\n",
    "    \"A_start_row\": 0,\n",
    "    \"A_end_row\" : A_prime.shape[0],\n",
    "    \"A_start_col\" : 0,\n",
    "    \"A_end_col\" : A_prime.shape[1],\n",
    "\n",
    "    \"X_start_row\": 0,\n",
    "    \"X_end_row\" : X_prime.shape[0],\n",
    "    \"X_start_col\" : 0,\n",
    "    \"X_end_col\" : X_prime.shape[1],\n",
    "\n",
    "    \"Y_start_row\": 0,\n",
    "    \"Y_end_row\" : Y_prime.shape[0],\n",
    "    \"Y_start_col\" : 0,\n",
    "    \"Y_end_col\" : Y_prime.shape[1],\n",
    "    \"weight\": 1,\n",
    "    \"loss\": 'MAE'\n",
    "}]\n",
    "\n",
    "X_regularization_loss_list = [\n",
    "    {\n",
    "        \"X_start_row\": 0,\n",
    "        \"X_end_row\" : X.shape[0],\n",
    "        \"X_start_col\" : 0,\n",
    "        \"X_end_col\" : X.shape[1],\n",
    "        \"penalty_type\" : 'L2',\n",
    "        \"alpha\": 0.001\n",
    "    },\n",
    "    {\n",
    "        \"X_start_row\": 0,\n",
    "        \"X_end_row\" : X.shape[0],\n",
    "        \"X_start_col\" : 0,\n",
    "        \"X_end_col\" : X.shape[1],\n",
    "        \"penalty_type\" : 'L1',\n",
    "        \"alpha\": 0.001\n",
    "    }\n",
    "]\n",
    "\n",
    "num_iterations=50000\n",
    "learning_rate=0.001\n",
    "result_val = predict(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, num_iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b5f6089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7739628040057225"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = np.hstack((result_val[0], A_prime))\n",
    "val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "val_pred = np.matmul(val_pred, beta)\n",
    "val_pred = tf.nn.softmax(val_pred).numpy()\n",
    "accuracy_score(np.array(label_test)-1, np.argmax(val_pred, axis=1))\n",
    "\n",
    "# accuracy_score(label_test, val_preds)\n",
    "\n",
    "# prob_val = np.exp(prob_val)/(1+np.exp(prob_val))\n",
    "# predictions_val = [1 if x >= 0.5 else 0 for x in prob_val]\n",
    "# accuracy_score(Y_test, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0fa749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([700, 50])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][:, 1:embedding_dim+1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions_val), confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a5846e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18571428571428572, 0.01859799713876967)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_embedding = result[0][:, 1:embedding_dim+1]\n",
    "X_train_embedding = X_train_embedding.numpy()\n",
    "\n",
    "X_test_embedding = result_val[0].numpy()\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, label_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(label_train, pred_logistic), accuracy_score(label_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57a025ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9785714285714285, 0.6738197424892703)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embedding = Y_train.T\n",
    "X_test_embedding = Y_test.T\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, label_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(label_train, pred_logistic), accuracy_score(label_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, pred_logistic_val), confusion_matrix(Y_train, pred_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+236), 328/(328+938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "1565/(1565+650), 1565/(1565+3805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.Variable([1,1,1])\n",
    "tf.where(temp!=1).shape[0]\n",
    "# tf.where([True, False, False, True]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(result[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][3:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7460b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.09003057, 0.24472848, 0.665241  ], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_info = Y_regularization_loss_list[2]\n",
    "\n",
    "# A_00, A_10, A_01, A_11 = loss_info['A_start_row'], loss_info['A_end_row'], loss_info['A_start_col'], loss_info['A_end_col']\n",
    "X_00, X_10, X_01, X_11 = loss_info['X_start_row'], loss_info['X_end_row'], loss_info['X_start_col'], loss_info['X_end_col']\n",
    "# Y_00, Y_10, Y_01, Y_11 = loss_info['Y_start_row'], loss_info['Y_end_row'], loss_info['Y_start_col'], loss_info['Y_end_col']\n",
    "\n",
    "\n",
    "# A_prime[A_00:A_10, A_01:A_11]\n",
    "# X_prime[X_00:X_10, X_01:X_11]\n",
    "# Y_prime[Y_00:Y_10, Y_01:Y_11]\n",
    "Y_prime[X_00:X_10, X_01:X_11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1.\n",
    "a = 0.\n",
    "current_min = 1.\n",
    "current_max = 38.\n",
    "\n",
    "def scale_class(val):\n",
    "    return (b-a)*(val-current_min)/(current_max-current_min)\n",
    "\n",
    "def scale_inv(val):\n",
    "    return val*(current_max-current_min) / (b-a) +current_min\n",
    "label_train_arr = np.array(label_train).reshape(-1,1)\n",
    "vfunc = np.vectorize(scale_class)\n",
    "label_train_arr_scaled = vfunc(label_train_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
