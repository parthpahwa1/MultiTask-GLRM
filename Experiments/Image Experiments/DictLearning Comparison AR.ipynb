{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8541f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from importlib import reload\n",
    "import scipy.io as sio\n",
    "import pkg_resources\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef278df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import MultiLearn_GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc9af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(filename):\n",
    "    return sio.loadmat(filename)\n",
    "\n",
    "def label_to_range(label):\n",
    "    \"\"\"\n",
    "    Convert label to range\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    label: list of integers\n",
    "        must be in the form of [1, 1, ..., 1, 2, 2, ..., 2, ..., C, C, ..., C]\n",
    "        i.e. nondecreasing numbers starting from 1, each element is greater\n",
    "        than the previous element by at most 1\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a list of intergers with C + 1 elements, start with 0\n",
    "    the i-th element is number of elements in label that equals to i\n",
    "        \n",
    "    \"\"\"\n",
    "    res = [0]\n",
    "    assert label[0] == 1, 'label must start with 1'\n",
    "    for i in range(1, len(label)):\n",
    "        if label[i] == label[i-1]:\n",
    "            continue\n",
    "        if label[i] == label[i-1] + 1:\n",
    "            res.append(i)\n",
    "        else:\n",
    "            assert False,\\\n",
    "                ('label[{}] and label[{}] must be equal or two consecutive '\n",
    "                 'integers, got {} and {}').format(\n",
    "                     i-1, i, label[i-1], label[i]\n",
    "                 )\n",
    "    res.append(len(label))\n",
    "    return res\n",
    "\n",
    "def get_block_row(matrix, block_indices, row_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of rows from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 0-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of rows in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    if isinstance(block_indices, int):\n",
    "        block_indices = [block_indices]\n",
    "    # if isinstance(block_indices, (list, np.ndarray, np.generic))\n",
    "    ids = []\n",
    "    for i in block_indices:\n",
    "        ids = ids + list(range(row_range[i], row_range[i+1]))\n",
    "    return matrix[ids, :].copy()\n",
    "\n",
    "def get_block_col(matrix, block_indices, col_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 1-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of columns in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    assert matrix.shape[1] == col_range[-1]\n",
    "    return get_block_row(matrix.T, block_indices, col_range).T\n",
    "\n",
    "def get_block_col(matrix, block_indices, col_range):\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from a matrix\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix: 2-d numpy array\n",
    "        block matrix\n",
    "    block_indices: integer of list of integers\n",
    "        indices of extracted blocks, 1-indexed. If indices is a list, return\n",
    "        the concatenation of all blocks\n",
    "    row_range: list of intergers\n",
    "        in the form of [0, c_1, c_1 + c_2, ..., c_1 + c_2 + ... + c_N]\n",
    "        where c_i is the number of columns in the i-th block\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a 2-d matrix\n",
    "    \"\"\"\n",
    "    assert matrix.ndim == 2, 'Expect to receive 2-d array input, got shape {}'.format(matrix.shape)\n",
    "    assert matrix.shape[1] == col_range[-1]\n",
    "    return get_block_row(matrix.T, block_indices, col_range).T\n",
    "\n",
    "def randperm(n):\n",
    "    \"\"\"\n",
    "    get a random permutation of range(n)\n",
    "    \"\"\"\n",
    "    return np.random.permutation(list(range(n)))\n",
    "\n",
    "def normc(A):\n",
    "    \"\"\"\n",
    "    normalize each column of A to have norm2 = 1\n",
    "    \"\"\"\n",
    "    return A / np.tile(np.sqrt(np.sum(A*A, axis=0)), (A.shape[0], 1))\n",
    "def vec(A):\n",
    "    # TODO: rewrite docstrings\n",
    "    \"\"\"\n",
    "    * Syntax: `a = vec(A)`\n",
    "    * Vectorization of a matrix. This function is a built-in function in some\n",
    "    recent MATLAB version.\n",
    "    \"\"\"\n",
    "    return A.flatten('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d196c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fn = pkg_resources.resource_filename('data/myYaleB' + '.mat')\n",
    "vars_dict = load_mat('./DICTOL_python-master/dictol/data/AR_EigenFace' + '.mat')\n",
    "\n",
    "Y_train     = normc(vars_dict['tr_dat'])\n",
    "Y_test      = normc(vars_dict['tt_dat'])\n",
    "label_train = vec(vars_dict['trls']).astype(int)\n",
    "label_test  = vec(vars_dict['ttls']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f31502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.03124342e-01, -5.04742099e-01, -5.21088138e-01, ...,\n",
       "         4.03009662e-01,  5.37699008e-01,  5.19834238e-01],\n",
       "       [-1.68132971e-02, -6.14705911e-02, -3.86886960e-02, ...,\n",
       "        -4.50126372e-01,  3.52874799e-01,  4.94850011e-02],\n",
       "       [-1.40089553e-01, -1.90421827e-01, -1.86757678e-01, ...,\n",
       "         2.65904848e-01,  1.48112766e-01,  3.16111680e-01],\n",
       "       ...,\n",
       "       [-1.51390691e-02,  5.43818716e-03,  2.02274256e-03, ...,\n",
       "         5.66781084e-03,  3.92088396e-03, -7.44471070e-04],\n",
       "       [ 7.01069493e-03,  2.04133921e-05, -1.65794632e-03, ...,\n",
       "        -6.24761669e-03,  2.30501228e-03,  3.25401237e-03],\n",
       "       [ 2.56713749e-03, -9.75658853e-03, -3.83385540e-03, ...,\n",
       "        -3.40278595e-03, -9.20898479e-03, -5.85581362e-03]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f51344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 699, (300, 700), (300, 699))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train), len(label_test), Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94fa300",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = max(max(label_train), max(label_test))\n",
    "label_train\n",
    "one_hot_targets = np.eye(nb_classes)[np.array(label_train)-1]\n",
    "TRAIN = np.hstack((Y_train.T, one_hot_targets))\n",
    "np.random.shuffle(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96597f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "epoch: 0\n",
      "iter: 0 Total loss: tf.Tensor(278050.950695167, shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 20:22:15.444931: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-01 20:22:15.445100: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 Total loss: tf.Tensor(236135.16184908355, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(196179.28542747494, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(159324.81252822842, shape=(), dtype=float64)\n",
      "iter: 400 Total loss: tf.Tensor(125400.58995623815, shape=(), dtype=float64)\n",
      "iter: 500 Total loss: tf.Tensor(94260.25456248817, shape=(), dtype=float64)\n",
      "iter: 600 Total loss: tf.Tensor(65947.86021424009, shape=(), dtype=float64)\n",
      "iter: 700 Total loss: tf.Tensor(40668.68296593254, shape=(), dtype=float64)\n",
      "iter: 800 Total loss: tf.Tensor(19225.766763653493, shape=(), dtype=float64)\n",
      "iter: 900 Total loss: tf.Tensor(5431.340507303888, shape=(), dtype=float64)\n",
      "iter: 982 Total loss: tf.Tensor(3724.4327931825064, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(3723.915308248109, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(3340.357063787492, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(3246.425828593472, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(3191.7778465718557, shape=(), dtype=float64)\n",
      "iter: 395 Total loss: tf.Tensor(3156.3405310683206, shape=(), dtype=float64)\n",
      "epoch: 1\n",
      "iter: 0 Total loss: tf.Tensor(3156.0260706036756, shape=(), dtype=float64)\n",
      "iter: 55 Total loss: tf.Tensor(2883.0728829370682, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2880.8028752263112, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(2715.369187630273, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(2674.396377568564, shape=(), dtype=float64)\n",
      "iter: 217 Total loss: tf.Tensor(2669.5794193375305, shape=(), dtype=float64)\n",
      "epoch: 2\n",
      "iter: 0 Total loss: tf.Tensor(2669.307248241488, shape=(), dtype=float64)\n",
      "iter: 17 Total loss: tf.Tensor(2574.5944849303087, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2570.387577110841, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(2463.795327584374, shape=(), dtype=float64)\n",
      "iter: 138 Total loss: tf.Tensor(2452.902489601674, shape=(), dtype=float64)\n",
      "epoch: 3\n",
      "iter: 0 Total loss: tf.Tensor(2452.657808536468, shape=(), dtype=float64)\n",
      "iter: 3 Total loss: tf.Tensor(2423.2867052852766, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2415.7000862213686, shape=(), dtype=float64)\n",
      "iter: 81 Total loss: tf.Tensor(2370.0978156880424, shape=(), dtype=float64)\n",
      "epoch: 4\n",
      "iter: 0 Total loss: tf.Tensor(2369.857499376831, shape=(), dtype=float64)\n",
      "iter: 19 Total loss: tf.Tensor(2268.6747680125372, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2266.016427716722, shape=(), dtype=float64)\n",
      "iter: 82 Total loss: tf.Tensor(2199.751152998393, shape=(), dtype=float64)\n",
      "epoch: 5\n",
      "iter: 0 Total loss: tf.Tensor(2199.524279281893, shape=(), dtype=float64)\n",
      "iter: 7 Total loss: tf.Tensor(2176.2545718219294, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2171.354729506168, shape=(), dtype=float64)\n",
      "iter: 63 Total loss: tf.Tensor(2136.465426770663, shape=(), dtype=float64)\n",
      "epoch: 6\n",
      "iter: 0 Total loss: tf.Tensor(2136.257002008297, shape=(), dtype=float64)\n",
      "iter: 31 Total loss: tf.Tensor(2083.083681584678, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2081.4539464631794, shape=(), dtype=float64)\n",
      "iter: 71 Total loss: tf.Tensor(2034.227993117126, shape=(), dtype=float64)\n",
      "epoch: 7\n",
      "iter: 0 Total loss: tf.Tensor(2034.0193920636646, shape=(), dtype=float64)\n",
      "iter: 19 Total loss: tf.Tensor(2017.089334831483, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(2015.1954866238148, shape=(), dtype=float64)\n",
      "iter: 60 Total loss: tf.Tensor(1980.2818263486074, shape=(), dtype=float64)\n",
      "epoch: 8\n",
      "iter: 0 Total loss: tf.Tensor(1980.0814049008243, shape=(), dtype=float64)\n",
      "iter: 34 Total loss: tf.Tensor(1957.026106676371, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1955.6647461159407, shape=(), dtype=float64)\n",
      "iter: 60 Total loss: tf.Tensor(1917.8414296131832, shape=(), dtype=float64)\n",
      "epoch: 9\n",
      "iter: 0 Total loss: tf.Tensor(1917.6572249061344, shape=(), dtype=float64)\n",
      "iter: 29 Total loss: tf.Tensor(1897.9719820371108, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1897.7471598178051, shape=(), dtype=float64)\n",
      "iter: 50 Total loss: tf.Tensor(1867.5257925415237, shape=(), dtype=float64)\n",
      "epoch: 10\n",
      "iter: 0 Total loss: tf.Tensor(1867.3386783555916, shape=(), dtype=float64)\n",
      "iter: 8 Total loss: tf.Tensor(1866.5336143223492, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1864.7693353795485, shape=(), dtype=float64)\n",
      "iter: 41 Total loss: tf.Tensor(1843.5806607064399, shape=(), dtype=float64)\n",
      "epoch: 11\n",
      "iter: 0 Total loss: tf.Tensor(1843.385098693106, shape=(), dtype=float64)\n",
      "iter: 6 Total loss: tf.Tensor(1839.435414323102, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1839.4613099198336, shape=(), dtype=float64)\n",
      "iter: 38 Total loss: tf.Tensor(1822.1460576951922, shape=(), dtype=float64)\n",
      "epoch: 12\n",
      "iter: 0 Total loss: tf.Tensor(1821.9666529225326, shape=(), dtype=float64)\n",
      "iter: 12 Total loss: tf.Tensor(1811.0014817949477, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1811.378887379959, shape=(), dtype=float64)\n",
      "iter: 37 Total loss: tf.Tensor(1794.2675084092255, shape=(), dtype=float64)\n",
      "epoch: 13\n",
      "iter: 0 Total loss: tf.Tensor(1794.0955757285142, shape=(), dtype=float64)\n",
      "iter: 10 Total loss: tf.Tensor(1790.1618527028925, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1790.5800469384278, shape=(), dtype=float64)\n",
      "iter: 37 Total loss: tf.Tensor(1774.9698340602763, shape=(), dtype=float64)\n",
      "epoch: 14\n",
      "iter: 0 Total loss: tf.Tensor(1774.8011497547216, shape=(), dtype=float64)\n",
      "iter: 6 Total loss: tf.Tensor(1773.7007252547205, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1773.454534456911, shape=(), dtype=float64)\n",
      "iter: 32 Total loss: tf.Tensor(1760.121280673133, shape=(), dtype=float64)\n",
      "epoch: 15\n",
      "iter: 0 Total loss: tf.Tensor(1759.9531809552295, shape=(), dtype=float64)\n",
      "iter: 17 Total loss: tf.Tensor(1753.5473850393744, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1753.3611986148421, shape=(), dtype=float64)\n",
      "iter: 32 Total loss: tf.Tensor(1740.6398372959497, shape=(), dtype=float64)\n",
      "epoch: 16\n",
      "iter: 0 Total loss: tf.Tensor(1740.4826280861578, shape=(), dtype=float64)\n",
      "iter: 4 Total loss: tf.Tensor(1742.021036103889, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1742.8299257449114, shape=(), dtype=float64)\n",
      "iter: 28 Total loss: tf.Tensor(1731.7929621967248, shape=(), dtype=float64)\n",
      "epoch: 17\n",
      "iter: 0 Total loss: tf.Tensor(1731.6256884208854, shape=(), dtype=float64)\n",
      "iter: 15 Total loss: tf.Tensor(1731.982288520982, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1729.656354926705, shape=(), dtype=float64)\n",
      "iter: 29 Total loss: tf.Tensor(1719.2601270380003, shape=(), dtype=float64)\n",
      "epoch: 18\n",
      "iter: 0 Total loss: tf.Tensor(1719.100215479063, shape=(), dtype=float64)\n",
      "iter: 16 Total loss: tf.Tensor(1721.3317360652113, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1721.7877456101844, shape=(), dtype=float64)\n",
      "iter: 28 Total loss: tf.Tensor(1710.3831928996735, shape=(), dtype=float64)\n",
      "epoch: 19\n",
      "iter: 0 Total loss: tf.Tensor(1710.2226940289372, shape=(), dtype=float64)\n",
      "iter: 6 Total loss: tf.Tensor(1713.3866646831916, shape=(), dtype=float64)\n",
      "iter: 0 Total loss: tf.Tensor(1715.2564716673035, shape=(), dtype=float64)\n",
      "iter: 25 Total loss: tf.Tensor(1705.7679461303862, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "reload(MultiLearn_GLRM)\n",
    "from MultiLearn_GLRM import Multi_Learn, generate_AXY\n",
    "from MultiLearn_GLRM.Params.semisupervised_params import Multilearn_GLRM_Semisupervised\n",
    "\n",
    "embedding_dim = 50\n",
    "n_class = nb_classes\n",
    "\n",
    "A_prime, X_prime, Y_prime = generate_AXY.get_semisupervised_glrm_train_form(TRAIN[:,:-nb_classes], TRAIN[:,-nb_classes:], n_class, embedding_dim)\n",
    "[GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions] = Multilearn_GLRM_Semisupervised(A_prime, X_prime, Y_prime, n_class)\n",
    "\n",
    "num_iterations=100000\n",
    "learning_rate=0.001\n",
    "result = Multi_Learn.alternating_minimization(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regulariation_list, Y_regulariation_list, X_grad_restrictions, Y_grad_restrictions, num_iterations, learning_rate, n_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14799cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob = tf.nn.softmax(np.matmul(result[0], result[1][:,0:n_class])).numpy()\n",
    "label_train_shuffled =  np.argmax(TRAIN[:,-nb_classes:], axis=1)\n",
    "accuracy_score(label_train_shuffled, np.argmax(train_prob, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "918b960c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Total loss: tf.Tensor(263173.32888632466, shape=(), dtype=float64)\n",
      "iter: 100 Total loss: tf.Tensor(216269.12043286263, shape=(), dtype=float64)\n",
      "iter: 200 Total loss: tf.Tensor(177081.93543409335, shape=(), dtype=float64)\n",
      "iter: 300 Total loss: tf.Tensor(143425.2013897097, shape=(), dtype=float64)\n",
      "iter: 400 Total loss: tf.Tensor(113744.45385915674, shape=(), dtype=float64)\n",
      "iter: 500 Total loss: tf.Tensor(87545.55420962205, shape=(), dtype=float64)\n",
      "iter: 600 Total loss: tf.Tensor(64631.32648868706, shape=(), dtype=float64)\n",
      "iter: 700 Total loss: tf.Tensor(45003.68748837462, shape=(), dtype=float64)\n",
      "iter: 800 Total loss: tf.Tensor(28876.919175245348, shape=(), dtype=float64)\n",
      "iter: 900 Total loss: tf.Tensor(16640.25161834191, shape=(), dtype=float64)\n",
      "iter: 1000 Total loss: tf.Tensor(8878.442087307472, shape=(), dtype=float64)\n",
      "iter: 1100 Total loss: tf.Tensor(5051.630033402949, shape=(), dtype=float64)\n",
      "iter: 1200 Total loss: tf.Tensor(3445.713200019267, shape=(), dtype=float64)\n",
      "iter: 1280 Total loss: tf.Tensor(2923.4455719719986, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "beta = result[1][1:,0:n_class]\n",
    "Y_final = result[1][1:embedding_dim+1,n_class:]\n",
    "\n",
    "A = Y_test.T\n",
    "A_prime =tf.constant(A)\n",
    "\n",
    "\n",
    "X = np.random.uniform(-1,1, (A.shape[0], embedding_dim))\n",
    "X_prime = X\n",
    "X_prime = tf.Variable(X_prime)\n",
    "\n",
    "Y_prime = Y_final\n",
    "X_regularization_loss_list, Y_regularization_loss_list = [], []\n",
    "\n",
    "GLRM_loss_list = [{\n",
    "    \"A_start_row\": 0,\n",
    "    \"A_end_row\" : A_prime.shape[0],\n",
    "    \"A_start_col\" : 0,\n",
    "    \"A_end_col\" : A_prime.shape[1],\n",
    "\n",
    "    \"X_start_row\": 0,\n",
    "    \"X_end_row\" : X_prime.shape[0],\n",
    "    \"X_start_col\" : 0,\n",
    "    \"X_end_col\" : X_prime.shape[1],\n",
    "\n",
    "    \"Y_start_row\": 0,\n",
    "    \"Y_end_row\" : Y_prime.shape[0],\n",
    "    \"Y_start_col\" : 0,\n",
    "    \"Y_end_col\" : Y_prime.shape[1],\n",
    "    \"weight\": 1,\n",
    "    \"loss\": 'MAE'\n",
    "}]\n",
    "\n",
    "X_regularization_loss_list = [\n",
    "    {\n",
    "        \"X_start_row\": 0,\n",
    "        \"X_end_row\" : X.shape[0],\n",
    "        \"X_start_col\" : 0,\n",
    "        \"X_end_col\" : X.shape[1],\n",
    "        \"penalty_type\" : 'L2',\n",
    "        \"alpha\": 0.001\n",
    "    },\n",
    "    {\n",
    "        \"X_start_row\": 0,\n",
    "        \"X_end_row\" : X.shape[0],\n",
    "        \"X_start_col\" : 0,\n",
    "        \"X_end_col\" : X.shape[1],\n",
    "        \"penalty_type\" : 'L1',\n",
    "        \"alpha\": 0.001\n",
    "    }\n",
    "]\n",
    "\n",
    "num_iterations=50000\n",
    "learning_rate=0.001\n",
    "result_val = Multi_Learn.predict(A_prime, X_prime, Y_prime, GLRM_loss_list, X_regularization_loss_list, Y_regularization_loss_list, num_iterations, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b5f6089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01859799713876967"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = np.hstack((result_val[0], A_prime))\n",
    "val_pred = np.hstack((val_pred, np.ones(shape=(val_pred.shape[0],1))))\n",
    "val_pred = np.matmul(val_pred, beta)\n",
    "val_pred = tf.nn.softmax(val_pred).numpy()\n",
    "accuracy_score(np.array(label_test)-1, np.argmax(val_pred, axis=1))\n",
    "\n",
    "# accuracy_score(label_test, val_preds)\n",
    "\n",
    "# prob_val = np.exp(prob_val)/(1+np.exp(prob_val))\n",
    "# predictions_val = [1 if x >= 0.5 else 0 for x in prob_val]\n",
    "# accuracy_score(Y_test, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0fa749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([700, 50])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][:, 1:embedding_dim+1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, predictions_val), confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a5846e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18571428571428572, 0.01859799713876967)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_embedding = result[0][:, 1:embedding_dim+1]\n",
    "X_train_embedding = X_train_embedding.numpy()\n",
    "\n",
    "X_test_embedding = result_val[0].numpy()\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, label_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(label_train, pred_logistic), accuracy_score(label_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57a025ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9785714285714285, 0.6738197424892703)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embedding = Y_train.T\n",
    "X_test_embedding = Y_test.T\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X_train_embedding, label_train)\n",
    "pred_logistic = clf.predict(X_train_embedding)\n",
    "pred_logistic_val = clf.predict(X_test_embedding)\n",
    "accuracy_score(label_train, pred_logistic), accuracy_score(label_test, pred_logistic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, pred_logistic_val), confusion_matrix(Y_train, pred_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+236), 328/(328+938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "1565/(1565+650), 1565/(1565+3805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.Variable([1,1,1])\n",
    "tf.where(temp!=1).shape[0]\n",
    "# tf.where([True, False, False, True]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(result[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][3:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7460b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.09003057, 0.24472848, 0.665241  ], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_info = Y_regularization_loss_list[2]\n",
    "\n",
    "# A_00, A_10, A_01, A_11 = loss_info['A_start_row'], loss_info['A_end_row'], loss_info['A_start_col'], loss_info['A_end_col']\n",
    "X_00, X_10, X_01, X_11 = loss_info['X_start_row'], loss_info['X_end_row'], loss_info['X_start_col'], loss_info['X_end_col']\n",
    "# Y_00, Y_10, Y_01, Y_11 = loss_info['Y_start_row'], loss_info['Y_end_row'], loss_info['Y_start_col'], loss_info['Y_end_col']\n",
    "\n",
    "\n",
    "# A_prime[A_00:A_10, A_01:A_11]\n",
    "# X_prime[X_00:X_10, X_01:X_11]\n",
    "# Y_prime[Y_00:Y_10, Y_01:Y_11]\n",
    "Y_prime[X_00:X_10, X_01:X_11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1.\n",
    "a = 0.\n",
    "current_min = 1.\n",
    "current_max = 38.\n",
    "\n",
    "def scale_class(val):\n",
    "    return (b-a)*(val-current_min)/(current_max-current_min)\n",
    "\n",
    "def scale_inv(val):\n",
    "    return val*(current_max-current_min) / (b-a) +current_min\n",
    "label_train_arr = np.array(label_train).reshape(-1,1)\n",
    "vfunc = np.vectorize(scale_class)\n",
    "label_train_arr_scaled = vfunc(label_train_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
